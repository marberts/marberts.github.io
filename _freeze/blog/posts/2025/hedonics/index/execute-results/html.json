{
  "hash": "c2e7ce8347375827143665448c3a5155",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hedonic imputation with one regression, not two\"\ndate: \"2025-10-27\"\ndate-modified: \"2025-11-26\"\ncategories:\n  - Index numbers\n  - Econometrics\n  - R\ndoi: 10.59350/2f0dq-zvs49\ndescription: Hedonic imputation is a standard method to compare prices over time when the composition of products also changes. In all cases I've seen, the method is implemented by using the fitted values from two regression models. I show how it can be done with one regression.\n---\n\nComparing housing prices over time is difficult because of all the heterogeneity in housing that can both affect prices and vary over time. The typical solution to this problem is to use a hedonic price index that attempts to model the relationship between housing characteristics and price, and uses this to control the change in these characteristics over time.\n\nAlthough there are several approaches to building a hedonic price index, the double imputation approach is usually seen as the best. Every presentation of this method that I have seen calculates the index by fitting two regression models and combining the fitted values from these models in a geometric index [e.g., @aizcorbe2014; @rppi2013; @rppi2020]. What I want to show here is that the double imputation index can be recovered from the coefficient in a linear regression. This makes it simpler to calculate the index and provides an easy strategy to estimate conventional standard errors.\n\n## Turning two regressions into one\n\nThe hedonic imputation model starts with two linear models, one for transactions in period 0,\n\n$$\n\\log(p_{i0}) = \\alpha_{0} + x_{i0} \\beta_{0} + u_{i0},\n$$ {#eq-laspeyres}\n\nand one for transactions in period 1,\n\n$$\n\\log(p_{i1}) = \\alpha_{1} + x_{i1} \\beta_{1} + e_{i1},\n$$ {#eq-paasche}\n\nwhere $x_{it}$ is a vector of characteristics that confound a change in price over time with a change in the composition of housing.\n\nThe Laspeyres hedonic imputation index, $I$, compares the predicted prices from @eq-paasche against those from @eq-laspeyres over the distribution of characteristics in period 0\n\n$$\n\\log(I) = \\alpha_{1} - \\alpha_{0} + \\bar{x}_{0} (\\beta_{1} - \\beta_{0}),\n$$ {#eq-lhi}\n\nwhere $\\bar{x}_{0}$ is the vector of average period 0 characteristics. This is equation 5.19 in @rppi2013.\n\n@eq-laspeyres and @eq-paasche can be nested to get a single linear model. Subtracting $\\bar{x}_{0}$ from the interaction term then gives @eq-lhi as a coefficient on a time dummy variable\n\n```{=latex}\n\\begin{align}\n\\log(p_{it}) &= \\alpha_{0} + x_{it} \\beta_{0} + t (\\alpha_{1} - \\alpha_{0} + x_{it} (\\beta_{1} - \\beta_{0})) + u_{it} + t(e_{it} - u_{it})\\\\\n\n&= \\alpha_{0} + t \\log(I) + x_{it} \\beta_{0} + t (x_{it} - \\bar{x}_{0}) (\\beta_{1} - \\beta_{0}) + \\varepsilon_{it},\n\\end{align}\n```\n\nwhere $\\varepsilon_{it} = u_{it} + t(e_{it} - u_{it})$. The Paasche hedonic imputation index follows along the same lines, replacing $\\bar{x}_{0}$ with $\\bar{x}_{1}$. The Fisher hedonic imputation index combines these two, which is the same as replacing $\\bar{x}_{0}$ with $\\bar{x}_{0} / 2 + \\bar{x}_{1} / 2$. Note that this reduces to the classic time-dummy hedonic index when $\\beta_{1} = \\beta_{0}$.[^1]\n\n[^1]: This type of regression model comes up in the literature on program evaluation as a way to estimate average treatment effects; see, e.g., @wooldridge2002 [section 18.3.1].\n\n## An example\n\nLet's go through an example to see this in action. As the goal is just to give an example, I'll make up some typical-looking transaction data for property sales with a few characteristics over two periods.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(15243)\n\nsales <- data.frame(\n  period = rep(0:1, c(120, 180)),\n  price = rlnorm(300),\n  area = runif(300, 800, 2500),\n  age = sample(1:80, 300, replace = TRUE),\n  amenity_score = runif(300)\n)\n\nhead(sales)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  period     price      area age amenity_score\n1      0 1.8931980 2415.7592  70    0.01447159\n2      0 0.9737266 2244.8349   5    0.59602963\n3      0 0.9860096 1937.4438  80    0.39965375\n4      0 1.4830738  989.7379  66    0.16038727\n5      0 0.3651522 2324.3656  50    0.82509594\n6      0 0.7955844 1930.3795  12    0.38836734\n```\n\n\n:::\n:::\n\n\nWe'll work with the following basic model relating price with characteristics in each period\n\n$$\n\\log(\\text{price}_{it}) = \\alpha_{t} + \\beta_{1t}\\text{age}_{it} + \\beta_{2t}\\text{area}_{it} + \\beta_{i3}\\text{area}_{it}^2 + \\beta_{i4}\\text{neighbourhoodscore}_{it} + \\varepsilon_{it}.\n$$\n\nThe two-regression approach for making the Laspeyres-imputation index fits two separate models for each time period and compares the average ratio of predicted prices over the distribution of housing characteristics for sales in period 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsales2 <- split(sales, ~period)\n\nmdl1 <- lm(log(price) ~ age + area + I(area^2) + amenity_score, sales2[[1]])\n\nmdl2 <- lm(log(price) ~ age + area + I(area^2) + amenity_score, sales2[[2]])\n\nlaspeyres <- exp(mean(predict(mdl2, sales2[[1]]) - predict(mdl1, sales2[[1]])))\n\nlaspeyres\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9367763\n```\n\n\n:::\n:::\n\n\nThe Paasche-imputation index does the same thing, just over the distribution of characteristics for sales in period 1, and the Fisher-imputation index combines the Laspeyres and Paasche indexes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaasche <- exp(mean(predict(mdl2, sales2[[2]]) - predict(mdl1, sales2[[2]])))\n\npaasche\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9376688\n```\n\n\n:::\n\n```{.r .cell-code}\nfisher <- sqrt(laspeyres * paasche)\n\nfisher\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9372224\n```\n\n\n:::\n:::\n\n\nTo make these indexes with one regression we need to remove the appropriate mean from the characteristics variables and interact them with the time dummy in the linear model. In each case the coefficient on the time dummy variable gives the same index as using two regressions. For simplicity, I'll just show the case of the Fisher index.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndm <- function(x) {\n  m0 <- mean(x[eval(substitute(period == 0), parent.frame())])\n  m1 <- mean(x[eval(substitute(period == 1), parent.frame())])\n  x - mean(c(m0, m1))\n}\n\nmdl_fisher <- lm(\n  log(price) ~ period +\n    age +\n    area +\n    I(area^2) +\n    amenity_score +\n    period:(dm(age) + dm(area) + dm(area^2) + dm(amenity_score)),\n  sales\n)\n\nall.equal(exp(coef(mdl_fisher)[\"period\"]), fisher, check.attributes = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\nRepresenting the Fisher index as the coefficient in a linear model also makes it easy to get the (delta method) standard error for the index. [^2]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(mdl_fisher)[\"period\"]) * sqrt(sandwich::vcovHC(mdl_fisher)[2, 2])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   period \n0.1009944 \n```\n\n\n:::\n:::\n\n\n[^2]: These standard error are approximate when the mean of the characteristics is calculated from the sample of data used to the fit the model.\n\nAdding weights to both the regression model and the index-number formulas is a simple extension. Continuing with the above example, suppose we want to weight by house price so that more expensive houses received a larger weight.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmdl1 <- lm(\n  log(price) ~ age + area + I(area^2) + amenity_score,\n  sales2[[1]],\n  weights = price\n)\n\nmdl2 <- lm(\n  log(price) ~ age + area + I(area^2) + amenity_score,\n  sales2[[2]],\n  weights = price\n)\n\nlaspeyres <- exp(\n  weighted.mean(\n    predict(mdl2, sales2[[1]]) - predict(mdl1, sales2[[1]]),\n    sales2[[1]]$price\n  )\n)\n\npaasche <- exp(\n  weighted.mean(\n    predict(mdl2, sales2[[2]]) - predict(mdl1, sales2[[2]]),\n    sales2[[2]]$price\n  )\n)\n\nfisher <- sqrt(laspeyres * paasche)\n```\n:::\n\n\nMaking the Fisher index with one regression just requires removing the weighted mean from the characteristics variables in the interaction term.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndm <- function(x) {\n  m0 <- eval(\n    substitute(weighted.mean(x[period == 0], price[period == 0])),\n    parent.frame()\n  )\n  m1 <- eval(\n    substitute(weighted.mean(x[period == 1], price[period == 1])),\n    parent.frame()\n  )\n  x - mean(c(m0, m1))\n}\n\nmdl_fisher <- lm(\n  log(price) ~ period +\n    age +\n    area +\n    I(area^2) +\n    amenity_score +\n    period:(dm(age) + dm(area) + dm(area^2) + dm(amenity_score)),\n  sales,\n  weights = price\n)\n\nall.equal(exp(coef(mdl_fisher)[\"period\"]), fisher, check.attributes = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n## Why two regressions can be better\n\nAs noted by @aizcorbe2014[Chapter 3], constructing the hedonic-imputation index with two regressions is more flexible than recovering an index from a regression coefficient. The trick of doing it with one regression works because the model is linear; using a non-linear regression model (however rare) may require fitting two models separately. Explicitly using the fitted values from two models to make price relatives also allows for the use of other index-number formulas, not just geometric ones.\n\nOne reason that I've not seen for the two-regression approach is that it's also more convenient to calculate product contributions when doing two regressions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlaspeyres_relatives <- exp(\n  predict(mdl2, sales2[[1]]) - predict(mdl1, sales2[[1]])\n)\ncontrib_laspeyres <- gpindex::geometric_contributions(laspeyres_relatives)\n\npaasche_relatives <- exp(\n  predict(mdl2, sales2[[2]]) - predict(mdl1, sales2[[2]])\n)\ncontrib_paasche <- gpindex::geometric_contributions(paasche_relatives)\n\ncontrib_fisher <- Map(\n  `*`,\n  gpindex::transmute_weights(0, 1)(c(laspeyres, paasche)),\n  list(contrib_laspeyres, contrib_paasche)\n)\n\nplot(\n  density(unlist(contrib_fisher)),\n  main = \"Distribution of sales contributions\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}