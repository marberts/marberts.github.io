[
  {
    "objectID": "blog/posts/2025/hedonics/index.html",
    "href": "blog/posts/2025/hedonics/index.html",
    "title": "Hedonic imputation with one regression, not two",
    "section": "",
    "text": "Comparing housing prices over time is difficult because of all the heterogeneity in housing that can both affect prices and vary over time. The typical solution to this problem is to use a hedonic price index that attempts to model the relationship between housing characteristics and price, and uses this to control the change in these characteristics over time.\nAlthough there are several approaches to building a hedonic price index, the double imputation approach is usually seen as the best. Every presentation of this method that I have seen calculates the index by fitting two regression models and combining the fitted values from these models in a geometric index (e.g., Aizcorbe 2014; ILO et al. 2013; IMF 2020). What I want to show here is that the double imputation index can be recovered from the coefficient in a linear regression. This makes it simpler to calculate the index and provides an easy strategy to estimate conventional standard errors."
  },
  {
    "objectID": "blog/posts/2025/hedonics/index.html#turning-two-regressions-into-one",
    "href": "blog/posts/2025/hedonics/index.html#turning-two-regressions-into-one",
    "title": "Hedonic imputation with one regression, not two",
    "section": "Turning two regressions into one",
    "text": "Turning two regressions into one\nThe hedonic imputation model starts with two linear models, one for transactions in period 0,\n\\[\n\\log(p_{i0}) = \\alpha_{0} + x_{i0} \\beta_{0} + u_{i0},\n\\tag{1}\\]\nand one for transactions in period 1,\n\\[\n\\log(p_{i1}) = \\alpha_{1} + x_{i1} \\beta_{1} + e_{i1},\n\\tag{2}\\]\nwhere \\(x_{it}\\) is a vector of characteristics that confound a change in price over time with a change in the composition of housing.\nThe Laspeyres hedonic imputation index, \\(I\\), compares the predicted prices from Equation¬†2 against those from Equation¬†1 over the distribution of characteristics in period 0\n\\[\n\\log(I) = \\alpha_{1} - \\alpha_{0} + \\bar{x}_{0} (\\beta_{1} - \\beta_{0}),\n\\tag{3}\\]\nwhere \\(\\bar{x}_{0}\\) is the vector of average period 0 characteristics. This is equation 5.19 in ILO et al. (2013).\nEquation¬†1 and Equation¬†2 can be nested to get a single linear model. Subtracting \\(\\bar{x}_{0}\\) from the interaction term then gives Equation¬†3 as a coefficient on a time dummy variable\n\\[\\begin{align}\n\\log(p_{it}) &= \\alpha_{0} + x_{it} \\beta_{0} + t (\\alpha_{1} - \\alpha_{0} + x_{it} (\\beta_{1} - \\beta_{0})) + u_{it} + t(e_{it} - u_{it})\\\\\n\n&= \\alpha_{0} + t \\log(I) + x_{it} \\beta_{0} + t (x_{it} - \\bar{x}_{0}) (\\beta_{1} - \\beta_{0}) + \\varepsilon_{it},\n\\end{align}\\]\nwhere \\(\\varepsilon_{it} = u_{it} + t(e_{it} - u_{it})\\). The Paasche hedonic imputation index follows along the same lines, replacing \\(\\bar{x}_{0}\\) with \\(\\bar{x}_{1}\\). The Fisher hedonic imputation index combines these two, which is the same as replacing \\(\\bar{x}_{0}\\) with \\(\\bar{x}_{0} / 2 + \\bar{x}_{1} / 2\\). Note that this reduces to the classic time-dummy hedonic index when \\(\\beta_{1} = \\beta_{0}\\).1"
  },
  {
    "objectID": "blog/posts/2025/hedonics/index.html#an-example",
    "href": "blog/posts/2025/hedonics/index.html#an-example",
    "title": "Hedonic imputation with one regression, not two",
    "section": "An example",
    "text": "An example\nLet‚Äôs go through an example to see this in action. As the goal is just to give an example, I‚Äôll make up some typical-looking transaction data for property sales with a few characteristics over two periods.\n\nset.seed(15243)\n\nsales &lt;- data.frame(\n  period = rep(0:1, c(120, 180)),\n  price = rlnorm(300),\n  area = runif(300, 800, 2500),\n  age = sample(1:80, 300, replace = TRUE),\n  amenity_score = runif(300)\n)\n\nhead(sales)\n\n  period     price      area age amenity_score\n1      0 1.8931980 2415.7592  70    0.01447159\n2      0 0.9737266 2244.8349   5    0.59602963\n3      0 0.9860096 1937.4438  80    0.39965375\n4      0 1.4830738  989.7379  66    0.16038727\n5      0 0.3651522 2324.3656  50    0.82509594\n6      0 0.7955844 1930.3795  12    0.38836734\n\n\nWe‚Äôll work with the following basic model relating price with characteristics in each period\n\\[\n\\log(\\text{price}_{it}) = \\alpha_{t} + \\beta_{1t}\\text{age}_{it} + \\beta_{2t}\\text{area}_{it} + \\beta_{i3}\\text{area}_{it}^2 + \\beta_{i4}\\text{neighbourhoodscore}_{it} + \\varepsilon_{it}.\n\\]\nThe two-regression approach for making the Laspeyres-imputation index fits two separate models for each time period and compares the average ratio of prediceted prices over the distribution of housing characteristics for sales in period 0.\n\nsales2 &lt;- split(sales, ~period)\n\nmdl1 &lt;- lm(log(price) ~ age + area + I(area^2) + amenity_score, sales2[[1]])\n\nmdl2 &lt;- lm(log(price) ~ age + area + I(area^2) + amenity_score, sales2[[2]])\n\nlaspeyres &lt;- exp(mean(predict(mdl2, sales2[[1]]) - predict(mdl1, sales2[[1]])))\n\nlaspeyres\n\n[1] 0.9367763\n\n\nThe Paasche-imputation index does the same thing, just over the distribution of characteristics for sales in period 1, and the Fisher-imputation index combines the Laspeyres and Paasche indexes.\n\npaasche &lt;- exp(mean(predict(mdl2, sales2[[2]]) - predict(mdl1, sales2[[2]])))\n\npaasche\n\n[1] 0.9376688\n\nfisher &lt;- sqrt(laspeyres * paasche)\n\nfisher\n\n[1] 0.9372224\n\n\nTo make these indexes with one regression we need to remove the appropriate mean from the characteristics variables and interact them with the time dummy in the linear model. In each case the coefficient on the time dummy variable gives the same index as using two regressions. For simplicitly, I‚Äôll just show the case of the Fisher index.\n\ndm &lt;- function(x) {\n  m0 &lt;- mean(x[eval(substitute(period == 0), parent.frame())])\n  m1 &lt;- mean(x[eval(substitute(period == 1), parent.frame())])\n  x - mean(c(m0, m1))\n}\n\nmdl_fisher &lt;- lm(\n  log(price) ~ period +\n    age +\n    area +\n    I(area^2) +\n    amenity_score +\n    period:(dm(age) + dm(area) + dm(area^2) + dm(amenity_score)),\n  sales\n)\n\nall.equal(exp(coef(mdl_fisher)[\"period\"]), fisher, check.attributes = FALSE)\n\n[1] TRUE\n\n\nRepresenting the Fisher index as the coefficient in a linear model also makes it easy to get the (delta method) standard error for the index. 2\n\nexp(coef(mdl_fisher)[\"period\"]) * sqrt(sandwich::vcovHC(mdl_fisher)[2, 2])\n\n   period \n0.1009944"
  },
  {
    "objectID": "blog/posts/2025/hedonics/index.html#why-two-regressions-can-be-better",
    "href": "blog/posts/2025/hedonics/index.html#why-two-regressions-can-be-better",
    "title": "Hedonic imputation with one regression, not two",
    "section": "Why two regressions can be better",
    "text": "Why two regressions can be better\nAs noted by Aizcorbe (2014, chap. 3), constructing the hedonic-imputation index with two regressions is more flexible than recovering an index from a regression coefficient. The trick of doing it with one regression works because the model is linear; using a non-linear regression model (however rare) may require fitting two models separately. Explicitly using the fitted values from two models to make price relatives also allows for the use of other index-number formulas, not just geometric ones.\nOne reason that I‚Äôve not seen for the two-regression approach is that it‚Äôs also more convenient to calculate product contributions when doing two regressions.\n\nlaspeyres_relatives &lt;- exp(\n  predict(mdl2, sales2[[1]]) - predict(mdl1, sales2[[1]])\n)\ncontrib_laspeyres &lt;- gpindex::geometric_contributions(laspeyres_relatives)\n\npaasche_relatives &lt;- exp(\n  predict(mdl2, sales2[[2]]) - predict(mdl1, sales2[[2]])\n)\ncontrib_paasche &lt;- gpindex::geometric_contributions(paasche_relatives)\n\ncontrib_fisher &lt;- Map(\n  `*`,\n  gpindex::transmute_weights(0, 1)(c(laspeyres, paasche)),\n  list(contrib_laspeyres, contrib_paasche)\n)\n\nplot(\n  density(unlist(contrib_fisher)),\n  main = \"Distribution of sales contributions\"\n)"
  },
  {
    "objectID": "blog/posts/2025/hedonics/index.html#footnotes",
    "href": "blog/posts/2025/hedonics/index.html#footnotes",
    "title": "Hedonic imputation with one regression, not two",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis type of regression model comes up in the literature on program evaluation as a way to estimate average treatment effects; see, e.g., Wooldridge (2002, sec. 18.3.1).‚Ü©Ô∏é\nThese standard error are approximate when the mean of the characteristics is calculated from the sample of data used to the fit the model.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/2025/variance-inequality/index.html",
    "href": "blog/posts/2025/variance-inequality/index.html",
    "title": "How does the difference between the arithmetic and geometric mean depend on variance?",
    "section": "",
    "text": "That the arithmetic mean of a set of number is larger than the geometric mean is a foundational result in the theory of inequalities. This is a useful result for index numbers in particular as it gives that, for the same data, an index based on an arithmetic mean will always be larger than the corresponding index based on the geometric mean.\nThe latest edition of the CPI manual says the following about the difference between the arithmetic and geometric mean and how it relates to variance (IMF et al. 2020, 2)\nThis seems like a great result that gives a way to easily think about the relationship between an index that uses an arithmetic mean to aggregate price relatives (Carli index) and one that uses a geometric mean (Jevons index). Unfortunately it‚Äôs not true‚Äîsee Lord (2002) for a neat way to generate counter examples. 1\nThe issue is that, for a vector of positive numbers \\(x\\in\\mathbf{R}_{n}^{++}\\), the difference between the arithmetic mean \\(\\mathfrak{A}(x)\\) and geometric mean \\(\\mathfrak{G}(x)\\) is only bounded by the variance (Bullen 2003, 156)\n\\[\n\\frac{\\text{var}(x)}{2 \\max(x)} \\leq \\mathfrak{A}(x) - \\mathfrak{G}(x) \\leq \\frac{\\text{var}(x)}{2 \\min(x)}.\n\\]\nFor two vectors \\(x\\) and \\(y\\), we have that \\(\\mathfrak{A}(y) - \\mathfrak{G}(y) &gt; \\mathfrak{A}(x) - \\mathfrak{G}(x)\\) if\n\\[\n\\text{var}(y) &gt; \\frac{\\max(y)}{\\min(x)}\\text{var}(x)\n\\tag{1}\\]\nand the opposite if\n\\[\n\\text{var}(y) &lt; \\frac{\\min(y)}{\\max(x)}\\text{var}(x)\n\\tag{2}\\]\nIf \\(\\max(y) &gt; \\min(x)\\) (what we should expect) then the difference between the arithmetic and geometric mean increases with a sufficiently large increase in variance. Similarly, if \\(\\min(y) &lt; \\max(x)\\) then the difference between the arithmetic and geometric mean decreases with a sufficiently large decrease in variance. If the support of the distribution is sufficiently narrow then the difference between the arithmetic and geometric mean will follow closely with the variance, and this is similar to the argument that generates the claim in the CPI manual (IMF et al. 2025, 131).\nWhat I want to understand is how the difference between the arithmetic and geometric mean changes for smaller changes in variance without placing restrictions on the support of the distribution. Let‚Äôs consider drawing a collection of samples from a fixed probability distribution to see how the difference between the arithmetic and geometric mean relates to variance among samples from that distribution. We‚Äôll make a few helper functions for this.\nvar_ineq &lt;- function(x) {\n  m &lt;- mean(x)\n  c(\n    var = mean((x - m)^2),\n    diff = m - exp(mean(log(x))),\n    min = min(x),\n    max = max(x)\n  )\n}\n\nsimulate_var_ineq &lt;- function(n, sim, dist) {\n  res &lt;- apply(matrix(dist(n * sim), nrow = n), 2, var_ineq)\n  res[, order(res[\"var\", ])]\n}\n\nprob_decrease &lt;- function(x) {\n  apply(\n    x,\n    2,\n    \\(z) {\n      cond &lt;- x[\"var\", ] &lt;= x[\"max\", ] / z[\"min\"] * z[\"var\"] |\n        x[\"var\", ] &gt;= x[\"min\", ] / z[\"max\"] * z[\"var\"]\n      x &lt;- x[, cond]\n      decrease &lt;- x[\"diff\", ] &lt; z[\"diff\"] & x[\"var\", ] &gt; z[\"var\"]\n      increase &lt;- x[\"diff\", ] &gt; z[\"diff\"] & x[\"var\", ] &lt; z[\"var\"]\n\n      mean(decrease | increase) * 100\n    }\n  )\n}\nThe scatter plot of the difference between the arithmetic and geometric mean and variance for a sample of size 10 shows that, although the difference tends to increase with variance, there are several instances where the opposite occurs.\nset.seed(15243)\n\nsim &lt;- simulate_var_ineq(10, 100, \\(n) rlnorm(n, sdlog = 0.25))\n\nplot(t(sim), ylab = \"arithmetic mean - geometric mean\", xlab = \"variance\")\nsymbols(0.13, 0.05, circles = 0.015, inches = FALSE, add = TRUE, lty = 2)\nsymbols(0.065, 0.03, circles = 0.01, inches = FALSE, add = TRUE, lty = 2)\nTo better understand this, let‚Äôs simulate the probability that the difference between the arithmetic and geometric mean decreases with variance, conditional on Equation¬†1 and Equation¬†2 not holding.\nres &lt;- simulate_var_ineq(10, 5000, \\(n) rlnorm(n, sdlog = 0.25)) |&gt;\n  prob_decrease()\n\nsummary(res)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   4.400   6.340   6.562   8.020  35.160\nOverall, the median of the conditional probability that the difference between the arithmetic and geometric mean decreases with variance is about 6.3%. This is a fairly small probability for the difference between the means to decrease when variance increases, although it depends on the underlying population from which samples are drawn. Drawing samples from a distribution with a wider support makes it more likely to see the the difference between the arithmetic and geometric mean decreases with variance.\nres &lt;- simulate_var_ineq(10, 5000, \\(n) runif(n, 0.25, 4)) |&gt;\n  prob_decrease()\n\nsummary(res)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.020   8.515  13.400  13.579  17.100  50.580\nAs the support of the distribution shrinks, the difference between the arithmetic and geometric mean follows the variance more closely and the probabiltity that the difference in means decreases as variance increases becomes small.\nres &lt;- simulate_var_ineq(10, 5000, \\(n) runif(n, 0.9, 1 / 0.9)) |&gt;\n  prob_decrease()\n\nsummary(res)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.800   1.140   1.194   1.500   4.560"
  },
  {
    "objectID": "blog/posts/2025/variance-inequality/index.html#footnotes",
    "href": "blog/posts/2025/variance-inequality/index.html#footnotes",
    "title": "How does the difference between the arithmetic and geometric mean depend on variance?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis can also apply to the difference between the arithmetic mean and harmonic mean, where it is often suggested that the difference between these means increases with variance (IMF et al. 2025, 131).‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Inflationary Tendencies",
    "section": "",
    "text": "Welcome to my blog. I write about topics in economics, statistics, and open source software (mostly so I don‚Äôt forget about it). All views expressed here are my own and do not necessarily reflect those of my employer or any affiliated organizations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow does the difference between the arithmetic and geometric mean depend on variance?\n\n\n\nInequalities\n\nIndex numbers\n\nR\n\n\n\nIt‚Äôs well known that the arithmetic mean is larger than the geometric mean, but how does the difference between these means relate to variance?\n\n\n\n\n\nNov 12, 2025\n\n\nSteve Martin\n\n\n\n\n\n\n\n\n\n\n\n\nHedonic imputation with one regression, not two\n\n\n\nIndex numbers\n\nEconometrics\n\nR\n\n\n\nHedonic imputation is a standard method to compares prices over time when the composition of products also changes. In all cases I‚Äôve seen, the method is implemented by using the fitted values from two regression models. I show how it can be done with one regression.\n\n\n\n\n\nOct 27, 2025\n\n\nSteve Martin\n\n\n\n\n\n\n\n\n\n\n\n\nWhat causes inflation?\n\n\n\nIndex numbers\n\nPython\n\n\n\nLong-term inflation requires something that increase prices and grow without bound (i.e., money supply). I show that the way that inflation is measured can itself be a source of inflation.\n\n\n\n\n\nOct 22, 2025\n\n\nSteve Martin\n\n\n\n\n\n\n\n\n\n\n\n\nDecomposing diversity indexes\n\n\n\nIndex numbers\n\nR\n\n\n\nA diversity index is a way to measure the prevalence of different species in an ecosystem. I show how methods from the price-index literature can be used to decompose a diversity index into the contribution of each species towards overall diversity.\n\n\n\n\n\nOct 19, 2025\n\n\nSteve Martin\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Research and Publications",
    "section": "",
    "text": "Martin, S. (2024). piar: Price Index Aggregation in R. Journal of Open Source Software, 9(101): 6781.\nKirby-McGregor, M. and Martin, S. (2019). An R package for calculating repeat-sale price indices. Romanian Statistical Review, 3/2019: 17-33.\n\n\n\n\n\nMartin, S. (2021). A note on general decompositions for price indexes. Prices Analytical Series. Statistics Canada Catalogue 62F0014M.\nMartin, S. (2020). Gearing up to stay open: Trends in businesses‚Äô needs for personal protective equipment since July. Statcan COVID-19: Data Insights for a Better Canada. Statistics Canada Catalogue 45-28-0001.\nMartin, S. (2020). Gearing up to restart: Businesses‚Äô need for personal protective equipment. Statcan COVID-19: Data Insights for a Better Canada. Statistics Canada Catalogue 45-28-0001.\nMartin, S. and Rouleau, B. (2020). An exploration of work, learning, and work-integrated learning in Canada using the Longitudinal and International Study of Adults. LISA Research Paper Series. Statistics Canada Catalogue 89-648-X.\nMartin, S. (2019). Methodology of the Residential Property Price Index (RPPI). Prices Analytical Series. Statistics Canada Catalogue 62F0014M.\nMartin, S. (2018). The association between job flexibility and job satisfaction. Insights on Canadian Society. Statistics Canada Catalogue 75-006-X.\nMartin, S. (2018). In sickness and in health: The association between health and household income. LISA Research Paper Series. Statistics Canada Catalogue 89-648-X.\n\n\n\n\n\nHeyes, A., Kapur, S., Kennedy, P., Martin, S., and Maxwell, J. (2020). But What Does it Mean? Competition between Products Carrying Alternative Green Labels when Consumers are Active Acquirers of Information. Journal of the Association of Environmental and Resource Economists, 7(2): 243-277.\nMartin, S. (2019). Moral management in competitive markets. Journal of Economics and Management Strategy, 28(3): 541‚Äì560.\nHeyes, A. and Martin, S. (2018). Inefficient social labels: Strategic proliferation and fragmentation in the market for certification. Journal of Economics and Management Strategy, 27(2): 206‚Äì220.\nHeyes, A., Lyon, T. P., and Martin, S. (2018). Salience games: Private politics when public attention is limited. Journal of Environmental Economics and Management, 88: 396‚Äì410.\nMartin, S. and Rivers, N. (2018). Information provision, market incentives, and household electricity consumption: Evidence from a large-scale field deployment. Journal of the Association of Environmental and Resource Economists, 5(1): 207‚Äì231.\nHeyes, A. and Martin, S. (2017). Social labeling by competing NGOs: A model with multiple issues and entry. Management Science, 63(6): 1800‚Äì1813.\nHeyes, A. and Martin, S. (2016). Fuzzy products. International Journal of Industrial Organization, 45: 1‚Äì9.\nHeyes, A. and Martin, S. (2015). NGO mission design. Journal of Economic Behavior & Organization, 119: 197‚Äì210.\n\n\n\n\n\nHa, X. and Martin, S. (2025). Modernizing Official Statistics: Transition to Open-Source Systems for Production of Producer Price Indexes. Voorburg Group on Service Statistics.\nBrown, C. and Martin, S. (2025). Interim Report: Survey of CPI Production Systems. UNECE Meeting of the Group of Experts on Consumer Price Indices.\nBurnett-Isaacs, K. and Martin, S. (2019). Unifying Approach to Statistics Canada¬¥s Residential Property Price Index. UNECE Ottawa Group on Price Indices.\nBurnett-Isaacs, K. and Martin, S. (2019). Constructing a Resale Residential Property Price Index for Vancouver using Repeat Sales. UNECE Ottawa Group on Price Indices."
  },
  {
    "objectID": "publications.html#publications",
    "href": "publications.html#publications",
    "title": "Research and Publications",
    "section": "",
    "text": "Martin, S. (2024). piar: Price Index Aggregation in R. Journal of Open Source Software, 9(101): 6781.\nKirby-McGregor, M. and Martin, S. (2019). An R package for calculating repeat-sale price indices. Romanian Statistical Review, 3/2019: 17-33.\n\n\n\n\n\nMartin, S. (2021). A note on general decompositions for price indexes. Prices Analytical Series. Statistics Canada Catalogue 62F0014M.\nMartin, S. (2020). Gearing up to stay open: Trends in businesses‚Äô needs for personal protective equipment since July. Statcan COVID-19: Data Insights for a Better Canada. Statistics Canada Catalogue 45-28-0001.\nMartin, S. (2020). Gearing up to restart: Businesses‚Äô need for personal protective equipment. Statcan COVID-19: Data Insights for a Better Canada. Statistics Canada Catalogue 45-28-0001.\nMartin, S. and Rouleau, B. (2020). An exploration of work, learning, and work-integrated learning in Canada using the Longitudinal and International Study of Adults. LISA Research Paper Series. Statistics Canada Catalogue 89-648-X.\nMartin, S. (2019). Methodology of the Residential Property Price Index (RPPI). Prices Analytical Series. Statistics Canada Catalogue 62F0014M.\nMartin, S. (2018). The association between job flexibility and job satisfaction. Insights on Canadian Society. Statistics Canada Catalogue 75-006-X.\nMartin, S. (2018). In sickness and in health: The association between health and household income. LISA Research Paper Series. Statistics Canada Catalogue 89-648-X.\n\n\n\n\n\nHeyes, A., Kapur, S., Kennedy, P., Martin, S., and Maxwell, J. (2020). But What Does it Mean? Competition between Products Carrying Alternative Green Labels when Consumers are Active Acquirers of Information. Journal of the Association of Environmental and Resource Economists, 7(2): 243-277.\nMartin, S. (2019). Moral management in competitive markets. Journal of Economics and Management Strategy, 28(3): 541‚Äì560.\nHeyes, A. and Martin, S. (2018). Inefficient social labels: Strategic proliferation and fragmentation in the market for certification. Journal of Economics and Management Strategy, 27(2): 206‚Äì220.\nHeyes, A., Lyon, T. P., and Martin, S. (2018). Salience games: Private politics when public attention is limited. Journal of Environmental Economics and Management, 88: 396‚Äì410.\nMartin, S. and Rivers, N. (2018). Information provision, market incentives, and household electricity consumption: Evidence from a large-scale field deployment. Journal of the Association of Environmental and Resource Economists, 5(1): 207‚Äì231.\nHeyes, A. and Martin, S. (2017). Social labeling by competing NGOs: A model with multiple issues and entry. Management Science, 63(6): 1800‚Äì1813.\nHeyes, A. and Martin, S. (2016). Fuzzy products. International Journal of Industrial Organization, 45: 1‚Äì9.\nHeyes, A. and Martin, S. (2015). NGO mission design. Journal of Economic Behavior & Organization, 119: 197‚Äì210.\n\n\n\n\n\nHa, X. and Martin, S. (2025). Modernizing Official Statistics: Transition to Open-Source Systems for Production of Producer Price Indexes. Voorburg Group on Service Statistics.\nBrown, C. and Martin, S. (2025). Interim Report: Survey of CPI Production Systems. UNECE Meeting of the Group of Experts on Consumer Price Indices.\nBurnett-Isaacs, K. and Martin, S. (2019). Unifying Approach to Statistics Canada¬¥s Residential Property Price Index. UNECE Ottawa Group on Price Indices.\nBurnett-Isaacs, K. and Martin, S. (2019). Constructing a Resale Residential Property Price Index for Vancouver using Repeat Sales. UNECE Ottawa Group on Price Indices."
  },
  {
    "objectID": "publications.html#other-research-activities",
    "href": "publications.html#other-research-activities",
    "title": "Research and Publications",
    "section": "Other research activities",
    "text": "Other research activities\n\nConference presentations\n\nStatistics Canada‚Äôs Price Measurement Advisory Committee (Ottawa, 2019 and 2025).\n52nd Annual Conference of the Canadian Economics Association (Montreal, 2018).\nAnnual meeting of the Canadian Public Economics Group (Montreal, 2016).\n50th Annual Conference of the Canadian Economics Association (Ottawa, 2016).\n4th Canadian Early Career Workshop in Environmental Economics (Ottawa, 2016).\n14th Annual International Industrial Organization Conference (Philadelphia, 2016).\nEAERE-FEEM-VIU European Summer School (Venice, 2015).\n5th World Congress of Environmental and Resource Economists (Istanbul, 2014).\n12th Annual International Industrial Organization Conference (Chicago, 2014).\n\n\n\nRefereed for\n\n\n\nCanadian Journal of Economics\n\n\nEnvironmental and Resource Economics\n\n\n\n\nJournal of the Association of Environmental and Resource Economists\n\n\nJournal of Economics and Management Strategy\n\n\n\n\nJournal of Environmental Economics and Management\n\n\nJournal of Open Source Software"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Steve Martin",
    "section": "",
    "text": "Hi there, I‚Äôm Steve üëã. Welcome to my personal website.\nI‚Äôm a principal researcher at Statistics Canada where I use economics and data science to measure the economy.\nI work on several side projects in my spare time building open source software to make better official statistics, particularly in the area of price statistics and inflation. Checkout software for more information.\nPrior to working at Statistics Canada, I completed my PhD in economics where I examined firms‚Äô corporate social responsibility and its implication for the efficient provision of public goods. Checkout research and publications for more information."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "Most price indexes are made with a two-step procedure, where period-over-period elementary indexes are first calculated for a collection of elementary aggregates at each point in time, and then aggregated according to a price index aggregation structure. These indexes can then be chained together to form a time series that gives the evolution of prices with respect to a fixed base period. This package contains a collection of functions that revolve around this work flow, making it easy to build standard price indexes, and implement the methods described by Balk (2008), von der Lippe (2007), and the CPI manual (2020) / PPI manual (2004) for bilateral price indexes.\n\n\n\n\n\n\n    \nSequential Poisson sampling is a variation of Poisson sampling for drawing probability-proportional-to-size samples with a given number of units, and is commonly used for price-index surveys. This package gives functions to draw stratified sequential Poisson samples according to the method by Ohlsson (1998), as well as other order sample designs by Ros√©n (1997), and generate approximate bootstrap replicate weights according to the generalized bootstrap method by Beaumont and Patak (2012).\n\n\n\n\n\n\n   \nTools to build and work with bilateral generalized-mean price indexes (and by extension quantity indexes), and indexes composed of generalized-mean indexes (e.g., superlative quadratic-mean indexes, GEKS). Covers the core mathematical machinery for making bilateral price indexes, computing price relatives, detecting outliers, and decomposing indexes, with wrappers for all common (and many uncommon) index-number formulas. Implements and extends many of the methods in Balk (2008), von der Lippe (2007), and the CPI manual (2020).\n\n\n\n\n\n\n  \nCalculate the matrices in Shiller (1991) that serve as the foundation for many repeat-sales price indexes."
  },
  {
    "objectID": "software.html#r-packages",
    "href": "software.html#r-packages",
    "title": "Software",
    "section": "",
    "text": "Most price indexes are made with a two-step procedure, where period-over-period elementary indexes are first calculated for a collection of elementary aggregates at each point in time, and then aggregated according to a price index aggregation structure. These indexes can then be chained together to form a time series that gives the evolution of prices with respect to a fixed base period. This package contains a collection of functions that revolve around this work flow, making it easy to build standard price indexes, and implement the methods described by Balk (2008), von der Lippe (2007), and the CPI manual (2020) / PPI manual (2004) for bilateral price indexes.\n\n\n\n\n\n\n    \nSequential Poisson sampling is a variation of Poisson sampling for drawing probability-proportional-to-size samples with a given number of units, and is commonly used for price-index surveys. This package gives functions to draw stratified sequential Poisson samples according to the method by Ohlsson (1998), as well as other order sample designs by Ros√©n (1997), and generate approximate bootstrap replicate weights according to the generalized bootstrap method by Beaumont and Patak (2012).\n\n\n\n\n\n\n   \nTools to build and work with bilateral generalized-mean price indexes (and by extension quantity indexes), and indexes composed of generalized-mean indexes (e.g., superlative quadratic-mean indexes, GEKS). Covers the core mathematical machinery for making bilateral price indexes, computing price relatives, detecting outliers, and decomposing indexes, with wrappers for all common (and many uncommon) index-number formulas. Implements and extends many of the methods in Balk (2008), von der Lippe (2007), and the CPI manual (2020).\n\n\n\n\n\n\n  \nCalculate the matrices in Shiller (1991) that serve as the foundation for many repeat-sales price indexes."
  },
  {
    "objectID": "software.html#python-packages",
    "href": "software.html#python-packages",
    "title": "Software",
    "section": "Python packages",
    "text": "Python packages\n\npysps\n\n\n\n \nSequential Poisson sampling is a variation of Poisson sampling for drawing probability-proportional-to-size samples with a given number of units, and is commonly used for price-index surveys. This package is a Python implementation of the {sps} R package."
  },
  {
    "objectID": "software.html#contributed-to",
    "href": "software.html#contributed-to",
    "title": "Software",
    "section": "Contributed to",
    "text": "Contributed to\n\n\n\n{accumulate}\n\n\n{bootstrapFP}\n\n\n{concstats}\n\n\n\n\nDVC\n\n\n{goodpractice}\n\n\n{gseries}\n\n\n\n\n{lintr}\n\n\nR (base and stats)\n\n\n{sampling}\n\n\n\n\n{tabulapdf}\n\n\n{tempodisco}"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Price statistics and index numbers\n\n\nR programming and data science\n\n\n\n\nIndustrial organization\n\n\nEnvironmental economics"
  },
  {
    "objectID": "about.html#interests",
    "href": "about.html#interests",
    "title": "About me",
    "section": "",
    "text": "Price statistics and index numbers\n\n\nR programming and data science\n\n\n\n\nIndustrial organization\n\n\nEnvironmental economics"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\n\nDegrees\n\nPhD Economics, University of Ottawa, 2013-2017.\nB.SocSc Economics, University of Ottawa, 2009-2012.\n\n\n\nOther education\n\nEuropean Summer School in Environmental Economics, Venice International University, 2015.\nVisiting Scholar, University of Michigan, 2015."
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About me",
    "section": "Work experience",
    "text": "Work experience\n\nEmployment\n\nPrincipal researcher, Statistics Canada, 2024‚Äìpresent\nData scientist, Government of Canada, 2022‚Äì2024.\nEconomist, Statistics Canada, 2017‚Äì2022.\nPart-time professor of economics, University of Ottawa, 2016‚Äì2018.\n\n\n\nTeaching\n\nA Course on Price Indices, Statistics Canada, 2019‚Äì2022.\nDigital Academy (lecture on R), Canada School of Public Service, Spring and Fall 2019.\nResearch Seminar in Economics of the Environment, University of Ottawa, Fall 2016 and Winter 2018."
  },
  {
    "objectID": "about.html#awards-and-prizes",
    "href": "about.html#awards-and-prizes",
    "title": "About me",
    "section": "Awards and Prizes",
    "text": "Awards and Prizes\n\nEconomic Statistics Field Shining Star Award, Statistics Canada, 2025.\nOutstanding Contribution Award, Statistics Canada, 2020.\nYouth Leadership Award, Statistics Canada, 2018.\nPierre Laberge prize for outstanding doctoral thesis, University of Ottawa, 2018.\nJoseph-Armande Bombardier Canadian Graduate Scholarship, SSHRC, 2015."
  },
  {
    "objectID": "blog/posts/2025/inflation/index.html",
    "href": "blog/posts/2025/inflation/index.html",
    "title": "What causes inflation?",
    "section": "",
    "text": "What causes inflation in prices over time? Increases in the money supply, of course. Although there are many reasons for increasing prices over time, money supply is one of the few things that can do so and grow without bound. Case closed, right? Not quite.\nIn practice we can‚Äôt perfectly observe how prices change over time and instead we must measure inflation with an index number. Ignoring all the details that arise in practice, the goal is usually to construct a chained Laspeyres or Fisher index. There‚Äôs a nice disclaimer in the CPI manual about potential issues with these formulas when prices bounce or oscillate, rather than grow monotonically (IMF et al. 2025, 24). What I want to show here is that this can be a source of perpetual inflation. This means that, for example, increases and decreases in market concentration over time, which would result in fluctuating prices, can result a price index measuring inflation, even when prices don‚Äôt cumulatively change over time."
  },
  {
    "objectID": "blog/posts/2025/inflation/index.html#setup",
    "href": "blog/posts/2025/inflation/index.html#setup",
    "title": "What causes inflation?",
    "section": "Setup",
    "text": "Setup\nLet‚Äôs start with a simple two-commodity model where a representative consumer has Cobb-Douglas preferences. We‚Äôll make a small class and mixin to make a Laspeyres and Fisher index given prices based on these preferences.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass IndexMixin:\n    def laspeyres(self, p1: np.ndarray, p0: np.ndarray) -&gt; float:\n        q0 = self.demand(p0)\n        return np.sum(p1 * q0) / np.sum(p0 * q0)\n\n    def paasche(self, p1: np.ndarray, p0: np.ndarray) -&gt; float:\n        q1 = self.demand(p1)\n        return np.sum(p1 * q1) / np.sum(p0 * q1)\n\n    def fisher(self, p1: np.ndarray, p0: np.ndarray) -&gt; float:\n        laspeyres = self.laspeyres(p1, p0)\n        paasche = self.paasche(p1, p0)\n        return np.sqrt(laspeyres * paasche)\n\n\nclass CobbDouglas(IndexMixin):\n    def __init__(self, alpha: np.ndarray, m: float):\n        self._alpha = np.asarray(alpha, dtype=np.float64)\n        self._alpha /= np.sum(self._alpha)\n        self._m = float(m)\n\n    def demand(self, p: np.ndarray) -&gt; np.ndarray:\n        if len(p) != len(self._alpha):\n            raise ValueError(f\"must supply prices for {len(self._alpha)} products\")\n        return self._alpha * self._m / p\n\nWe‚Äôll also make a function to oscillate prices. The idea is to form a chain of index values that starts with both products having a price of [1, 1], switches prices between [1, 1.1] and [1.1, 1] some number of times, and ends with prices back at [1, 1]. As a chained index is just the cumulative product of these index values, we can decompose the chained index into the product of the first and last change in price, and the product of the oscillations. What‚Äôs necessary to drive inflation is that the product of the oscillations is greater than 1.\nWe‚Äôll also make a second function that does a more complex oscillation that we‚Äôll use later.\n\ndef bounce(index) -&gt; tuple[np.float64]:\n    initial = [1, 1]\n    p1 = [1, 1.1]\n    p2 = [1.1, 1]\n    i = index(p1, initial) * index(initial, p1)\n    b = index(p2, p1) * index(p1, p2)\n    return i, b\n\n\ndef bounce2(index) -&gt; tuple[np.float64]:\n    initial = [1, 1]\n    p1 = [1, 1.1]\n    p2 = [1.2, 1]\n    p3 = [1.1, 1]\n    i = index(p1, initial) * index(initial, p1)\n    b = index(p2, p1) * index(p3, p2) * index(p1, p3)\n    return i, b"
  },
  {
    "objectID": "blog/posts/2025/inflation/index.html#inflation-due-to-measurement",
    "href": "blog/posts/2025/inflation/index.html#inflation-due-to-measurement",
    "title": "What causes inflation?",
    "section": "Inflation due to measurement",
    "text": "Inflation due to measurement\nLet‚Äôs start by generating some preferences and giving our representative consumer a fixed income, then simulating how the chained Laspeyres index evolves as prices bounce around.\n\nu = CobbDouglas([1, 2], 100)\n\nres = bounce(u.laspeyres)\n\noscillate = [res[0] * res[1]**n for n in range(20)]\n\nfig, ax = plt.subplots()\nax.plot(oscillate)\nplt.xticks(range(0, 20, 2))\nplt.show()\n\n\n\n\n\n\n\n\nHere we see that, despite prices starting and ending at the same level, the chained Laspeyres index shows that prices have increased over time. This happens because each oscillation registers an increase in prices (about 0.8%), and these compound to show that prices are increasing over time. Note that the culprit here is the well-known substitution bias in the Laspeyres index; if there was no substitution bias then the index would be transitive with Cobb-Douglas preferences and (correctly) show no change in prices over time. Instead, this happens with Leontief preferences.\n\nclass Leontief(IndexMixin):\n    def __init__(self, m: float):\n        self._m = float(m)\n\n    def demand(self, p: np.ndarray) -&gt; np.ndarray:\n        return np.repeat(self._m / np.sum(p), len(p))\n\nbounce(Leontief(100).laspeyres)\n\n(np.float64(1.0), np.float64(1.0))\n\n\nBoth components of the chained index‚Äîthe first and last change in price and the part due to oscillations‚Äîshow no change in price.\nWe can get the same behavior from the Fisher index, albeit with a more complex form of oscillation. (Using the simple oscillation would show no change in prices over time because the Fisher index satisfies the time-reversal property.)\n\nres = bounce2(u.fisher)\n\noscillate = [res[0] * res[1] ** n for n in range(20)]\n\nfig, ax = plt.subplots()\nax.plot(oscillate)\nplt.xticks(range(0, 20, 2))\nplt.show()\n\n\n\n\n\n\n\n\nEach oscillation registers a 0.02% increase in prices. Note that this behavior from the Fisher index is sensitive to the parameters in the Cobb-Douglas utility function and it‚Äôs also possible to get that prices decreases over time.\n\nu = CobbDouglas([2, 1], 100)\nres = bounce2(u.fisher)\nprint(res)\n\n(np.float64(1.0), np.float64(0.9998308882582081))\n\n\nOverall, this example shows that more than just money supply can drive our measurement of inflation, even if increasing money supply is the only true cause of inflation."
  },
  {
    "objectID": "blog/posts/2025/diversity/index.html",
    "href": "blog/posts/2025/diversity/index.html",
    "title": "Decomposing diversity indexes",
    "section": "",
    "text": "A diversity index is a way to measure the prevalence of different species in an ecosystem. Although these arise naturally in ecology, diversity indexes show up elsewhere as well. In economics, for example, we can think of diversity as related to the market concentration of firms (species) in an industry (ecosystem). What I want to show here is how we can use some of the machinery from the world of price and quantity indexes to decompose a diversity index into the contribution of each species towards overall diversity."
  },
  {
    "objectID": "blog/posts/2025/diversity/index.html#what-is-diversity-anyway",
    "href": "blog/posts/2025/diversity/index.html#what-is-diversity-anyway",
    "title": "Decomposing diversity indexes",
    "section": "What is diversity, anyway?",
    "text": "What is diversity, anyway?\nDiversity is a tricky concept to formalize. Up until writing this post, I would have said it was just the number of species in an ecosystem. In his seminal paper, Hill (1973) considers a family diversity indexes that give a measure of the effective number of species in an ecosystem‚Äîthat is, the number of species that would be present in an ecosystem if all species were equally prevalent. Mathemetically, if there are \\(n\\) species and the \\(i\\)-th species appears with probability \\(p_{i}\\), then the diversity index of order \\(\\alpha\\) is\n\\[\nN_{\\alpha}(p_{1}, \\ldots, p_{n}) = \\left(\\sum_{i=1}^{n}p_{i}^{\\alpha}\\right)^{\\frac{1}{1 - \\alpha}}.\n\\]\nDifferent values for \\(\\alpha\\) yield different indexes; for example, \\(N_{0}\\) measures diversity by the total number of species \\(n\\), also known as the richness of the ecosystem. As a function of \\(\\alpha\\), \\(N_{\\alpha}\\) is a continuously decreasing function that maps values in \\([0, \\infty)\\) onto \\([n, 1 / \\max(p_{1}, \\ldots, p_{n}))\\). We can see this with an example of an ecosystem with 10 species.\n\ndiversity_index &lt;- function(x, alpha) {\n  if (alpha != 1) {\n    sum(x^alpha)^(1 / (1 - alpha))\n  } else {\n    exp(-sum(p * log(p)))\n  }\n}\n\nset.seed(54321)\n\np &lt;- sort(gpindex::scale_weights(rlnorm(10)))\n\nhist(p, main = \"Abundance of species in an ecosystem\")\n\n\n\n\n\n\n\nalphas &lt;- seq(0, 5, 0.25)\nindex &lt;- sapply(alphas, \\(a) diversity_index(p, a))\n\nplot(\n  alphas,\n  index,\n  ylim = c(0, 10),\n  xlab = \"ùõº\",\n  ylab = \"Index\",\n  main = \"Diversity decreases with ùõº\"\n)\nabline(1 / max(p), 0, lty = \"dashed\")\n\n\n\n\n\n\n\n\nWith a bit of rearranging, we can see that \\(N_\\alpha\\) is the reciprocal of the generalized mean of \\((p_{1}, \\ldots, p_{n})\\) with these same values as weights\n\\[\nN_{\\alpha}(p_{1}, \\ldots, p_{n}) = 1 / \\left(\\sum_{i=1}^{n} p_{i}^{\\alpha - 1} p_{i}\\right)^{\\frac{1}{\\alpha - 1}}.\n\\]\nFormulating \\(N_{\\alpha}\\) as a generalized mean shows a clear link between diversity indexes and concentration indexes, as \\(N_{2}\\) is the reciprocal of the well-known Simpson index (or Herfindahl‚ÄìHirschman index if you‚Äôre an economist). (It also shows a link with measures of entropy, as \\(\\log(N_{\\alpha})\\) is a generalization of Shannon entropy.) What makes a diversity index different from a measure of concentration (or entropy) is that it expresses diversity in terms of the effective size of the ecosystem that would give rise to a particular concentration of species if species were all equally abundant. Intuitively, \\(1 / p_{i}\\) gives the effective size of the ecosystem if all species were as prevalent as species \\(i\\). Rather than considering a single species, \\(N_{a}\\) uses the average abundance across all species to arrive at a measure of diversity."
  },
  {
    "objectID": "blog/posts/2025/diversity/index.html#decomposing-diversity",
    "href": "blog/posts/2025/diversity/index.html#decomposing-diversity",
    "title": "Decomposing diversity indexes",
    "section": "Decomposing diversity",
    "text": "Decomposing diversity\nHill (1973) notes that different choices for \\(\\alpha\\) imply different sensitivities to rare versus abundant species in an ecosystem. Setting \\(\\alpha = 0\\) means that diversity depends only on the number of species, no matter how rare some may be, whereas when \\(\\alpha \\rightarrow \\infty\\) then only the most prevalent species influences diversity. We can go one step further by decomposing \\(N_{\\alpha}\\) so that it‚Äôs represented as an arithmetic mean of the effective size of each species \\(1 / p_{i}\\) and we can see the contribution of each species towards total diversity. We‚Äôll do this by borrowing some of the machinery from price and quantity indexes to derive weights \\((w_{1}, \\ldots, w_{n})\\) such that\n\\[\nN_{\\alpha}(p_{1}, \\ldots, p_{n}) = \\sum_{i=1}^{n} w_{i} / p_{i}.\n\\]\nThe core tool to do this comes from my {gpindex} package.\n\ndiversity_weights &lt;- function(x, alpha) {\n  gpindex::transmute_weights(alpha - 1, -1)(x, x)\n}\n\nWhen \\(\\alpha = 0\\), each species contributes the same amount to overall diversity.\n\ndiversity_weights(p, 0) / p\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\n\nIncreasing \\(\\alpha\\) to 2, the measure of diversity decreases and more weight is shifted towards more abundant species.\n\ndiversity_weights(p, 2) / p\n\n [1] 0.02204630 0.02298373 0.04003915 0.04733940 0.05467209 0.07962440\n [7] 0.10013170 0.14336078 0.48334916 1.48242257\n\n\nAs alpha becomes larger, rare species get a small weight and contribute little towards overall diversity.\n\ndiversity_weights(p, 5)\n\n [1] 4.429620e-05 4.817851e-05 1.481826e-04 2.083463e-04 2.795183e-04\n [6] 6.049503e-04 9.729488e-04 2.068354e-03 3.261787e-02 9.630074e-01\n\ndiversity_weights(p, 5) / p\n\n [1] 0.004974804 0.005190128 0.009163420 0.010897035 0.012658720 0.018811300\n [7] 0.024058228 0.035722328 0.167085953 1.608432485\n\n\nThis gives a different way to view the prevalence of a species, not just by their abundance but by how their abundance contributes towards overall diversity in an ecosystem."
  }
]